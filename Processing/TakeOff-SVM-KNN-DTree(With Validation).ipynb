{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3390L, 10L)\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import numpy as np\n",
    "\n",
    "#Connect to mongoDB and get data from collection\n",
    "client = pymongo.MongoClient() \n",
    "db = client.TrainingDataDB \n",
    "\n",
    "currentExpData = []\n",
    "discExpData = []\n",
    "for i in range(1,33):\n",
    "    expCollectionName = \"TakeOffExp\"+str(i)\n",
    "    \n",
    "    expCollection = db[expCollectionName]\n",
    "    \n",
    "    expDocuments = expCollection.find({})\n",
    "    currentTrialData = []\n",
    "    for expDocument in expDocuments:\n",
    "        expDataArray = expDocument['data']\n",
    "        currentExpData.append(expDataArray)\n",
    "        #For breaking the data into smaller pieces\n",
    "        currentTrialData.append(expDataArray)\n",
    "    currTrial = np.array(currentTrialData) #make it into numpy array\n",
    "    discCurrTrial = np.array([currTrial[x:x+30] for x in range(0, len(currTrial), 30)])\n",
    "    #print discCurrTrial\n",
    "    #print \"-------------------\"\n",
    "    #print currTrial.shape\n",
    "    #print len(discCurrTrial)\n",
    "    discExpData.append(discCurrTrial)\n",
    "    #print discExpData\n",
    "\n",
    "#print currentExpData\n",
    "#print discExpData\n",
    "\n",
    "expertDataArray = np.array(currentExpData)\n",
    "discExpDataArray = np.array(discExpData)\n",
    "print expertDataArray.shape\n",
    "#print discExpDataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Trial #3\n",
      "(4695L, 10L)\n"
     ]
    }
   ],
   "source": [
    "currentNovData = []      \n",
    "for j in range (1,57):\n",
    "    novCollectionName = \"TakeOffNov\"+str(j)\n",
    "    \n",
    "    novCollection = db[novCollectionName]\n",
    "    \n",
    "    novDocuments = novCollection.find({})\n",
    "    if j==3:\n",
    "        print \"Skipping Trial #3\" #Due to null values from the sensor which cause the classifier to crash\n",
    "    else:\n",
    "        for novDocument in novDocuments:\n",
    "            novDataArray = novDocument['data']\n",
    "            currentNovData.append(novDataArray)\n",
    "            currTrial = np.array(currentNovData)\n",
    "            #print currTrial.shape\n",
    "\n",
    "#print currentNovData\n",
    "\n",
    "noviceDataArray = np.array(currentNovData)\n",
    "print noviceDataArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8085L, 10L)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Consolidate all data \n",
    "allData = np.concatenate((expertDataArray,noviceDataArray), axis=0)\n",
    "allData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#Create labels\n",
    "expert_rows, expert_columns = expertDataArray.shape\n",
    "#print expert_rows\n",
    "expert_labels = np.zeros(expert_rows,)\n",
    "#print expert_labels\n",
    "novice_rows, novice_columns = noviceDataArray.shape\n",
    "#print novice_rows\n",
    "novice_labels = np.ones(novice_rows,)\n",
    "#print novice_labels\n",
    "\n",
    "all_labels = np.concatenate((expert_labels,novice_labels), axis=0)\n",
    "print all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835497835498\n",
      "0.0269999504089\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, cross_validation, neighbors, svm, tree\n",
    "Data_train, Data_test, Labels_train, Labels_test = cross_validation.train_test_split(allData, all_labels, test_size=0.2)\n",
    "\n",
    "import time\n",
    "\n",
    "#KNN\n",
    "knn_classifier = neighbors.KNeighborsClassifier()\n",
    "start_time = time.time()\n",
    "knn_classifier.fit(Data_train, Labels_train)\n",
    "#knn_classifier.fit(Data_test, Labels_test)\n",
    "knn_score = knn_classifier.score(Data_test, Labels_test)\n",
    "stop_time = time.time()\n",
    "knn_runtime = stop_time-start_time\n",
    "print knn_score\n",
    "print knn_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.810760667904\n",
      "21.9049999714\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "svm_classifier = svm.SVC(kernel='linear', C = 1.0)\n",
    "start_time = time.time()\n",
    "svm_classifier.fit(Data_train, Labels_train)\n",
    "#svm_classifier.fit(Data_test, Labels_test)\n",
    "svm_score = svm_classifier.score(Data_test, Labels_test)\n",
    "stop_time = time.time()\n",
    "svm_runtime = stop_time-start_time\n",
    "print svm_score\n",
    "print svm_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.805194805195\n",
      "0.0440001487732\n"
     ]
    }
   ],
   "source": [
    "#DTree\n",
    "dt_classifier = tree.DecisionTreeClassifier()\n",
    "start_time = time.time()\n",
    "dt_classifier.fit(Data_train, Labels_train)\n",
    "#dt_classifier.fit(Data_test, Labels_test)\n",
    "dtree_score = dt_classifier.score(Data_test, Labels_test)\n",
    "stop_time = time.time()\n",
    "dt_runtime = stop_time-start_time\n",
    "print dtree_score\n",
    "print dt_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108L, 10L)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name = \"TakeOffNov61\"\n",
    "collection = db[collection_name]\n",
    "documents = collection.find({})\n",
    "currentTrialData = []\n",
    "for document in documents:\n",
    "    dataArray = document['data']\n",
    "    currentTrialData.append(dataArray)\n",
    "\n",
    "dataArray = np.array(currentTrialData)\n",
    "dataArray.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novice\n",
      "0.888888888889\n"
     ]
    }
   ],
   "source": [
    "#predict using KNN\n",
    "knn_result = knn_classifier.predict(dataArray)\n",
    "#print result\n",
    "\n",
    "length = len(knn_result)\n",
    "#print length\n",
    "num_ones = np.count_nonzero(knn_result,axis=0)\n",
    "#print num_ones\n",
    "if (num_ones/float(length)) > 0.50:\n",
    "    print \"Novice\"\n",
    "else:\n",
    "    print \"Expert\"\n",
    "print num_ones/float(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novice\n",
      "0.981481481481\n"
     ]
    }
   ],
   "source": [
    "#predict using SVM\n",
    "svm_result = svm_classifier.predict(dataArray)\n",
    "length = len(svm_result)\n",
    "#print length\n",
    "num_ones = np.count_nonzero(svm_result,axis=0)\n",
    "#print num_ones\n",
    "if (num_ones/float(length)) > 0.50:\n",
    "    print \"Novice\"\n",
    "else:\n",
    "    print \"Expert\"\n",
    "print num_ones/float(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novice\n",
      "0.759259259259\n"
     ]
    }
   ],
   "source": [
    "#predict using Decision Tree\n",
    "dt_result = dt_classifier.predict(dataArray)\n",
    "length = len(dt_result)\n",
    "#print length\n",
    "num_ones = np.count_nonzero(dt_result,axis=0)\n",
    "#print num_ones\n",
    "if (num_ones/float(length)) > 0.50:\n",
    "    print \"Novice\"\n",
    "else:\n",
    "    print \"Expert\"\n",
    "print num_ones/float(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

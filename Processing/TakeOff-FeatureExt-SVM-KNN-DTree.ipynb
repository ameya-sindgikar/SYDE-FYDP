{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15L, 20L)\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import numpy as np\n",
    "\n",
    "#Connect to mongoDB and get data from collection\n",
    "client = pymongo.MongoClient() \n",
    "db = client.TrainingDataDB \n",
    "\n",
    "currentExpData = []\n",
    "extractedExpData = []\n",
    "for i in range(1,16):\n",
    "    expCollectionName = \"TakeOffExp\"+str(i)\n",
    "    \n",
    "    expCollection = db[expCollectionName]\n",
    "    \n",
    "    expDocuments = expCollection.find({})\n",
    "    currentTrialData = []\n",
    "    for expDocument in expDocuments:\n",
    "        expDataArray = expDocument['data']\n",
    "        currentExpData.append(expDataArray)\n",
    "        currentTrialData.append(expDataArray)\n",
    "    currTrial = np.array(currentTrialData) #make it into numpy array\n",
    "    #print currTrial.shape\n",
    "    currTrialStd = np.std(currTrial, axis=0)\n",
    "    #print \"Standard deviation--------------------------------------------------------------------\"\n",
    "    #print currTrialStd\n",
    "    currTrialMean = np.mean(currTrial, axis=0)\n",
    "    #print \"Mean----------------------------------------------------------------------------------\"\n",
    "    #print currTrialMean\n",
    "    #currTrialAllExtData = np.array(zip(currTrialStd, currTrialMean))\n",
    "    currTrialAllExtData = np.concatenate((currTrialStd, currTrialMean))\n",
    "    #print \"Concatenated---------------------------------------------------------------------------\"\n",
    "    #print currTrialAllExtData\n",
    "    #print \"Appended-------------------------------------------------------------------------------\"\n",
    "    #print currTrialAllExtData.shape\n",
    "    extractedExpData.append(currTrialAllExtData)\n",
    "    #print extractedExpData\n",
    "    #print \"END-------------------------------------------------------------------------------------\"\n",
    "\n",
    "expertDataArray = np.array(currentExpData)\n",
    "expertExtractedDataArray = np.array(extractedExpData)\n",
    "print expertExtractedDataArray.shape\n",
    "#print expertDataArray.shape\n",
    "#print discExpDataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Trial #3\n",
      "(19L, 20L)\n"
     ]
    }
   ],
   "source": [
    "currentNovData = []\n",
    "extractedNovData = []\n",
    "for j in range (1,21):\n",
    "    novCollectionName = \"TakeOffNov\"+str(j)\n",
    "    \n",
    "    novCollection = db[novCollectionName]\n",
    "    \n",
    "    novDocuments = novCollection.find({})\n",
    "    currentNovTrialData = []\n",
    "    if j==3:\n",
    "        print \"Skipping Trial #3\" #Due to null values from the sensor which cause the classifier to crash\n",
    "    else:\n",
    "        for novDocument in novDocuments:\n",
    "            novDataArray = novDocument['data']\n",
    "            currentNovData.append(novDataArray)\n",
    "            currentNovTrialData.append(novDataArray)\n",
    "        currNovTrial = np.array(currentNovTrialData) #make it into numpy array\n",
    "        #print currNovTrial.shape\n",
    "        currNovTrialStd = np.std(currNovTrial, axis=0)\n",
    "        #print \"Standard deviation--------------------------------------------------------------------\"\n",
    "        #print currNovTrialStd\n",
    "        currNovTrialMean = np.mean(currNovTrial, axis=0)\n",
    "        #print \"Mean----------------------------------------------------------------------------------\"\n",
    "        #print currNovTrialMean\n",
    "        #currTrialAllExtData = np.array(zip(currNovTrialStd, currNovTrialMean))\n",
    "        currNovTrialAllExtData = np.concatenate((currNovTrialStd, currNovTrialMean),axis=0)\n",
    "        #print \"Concatenated---------------------------------------------------------------------------\"\n",
    "        #print currNovTrialAllExtData\n",
    "        #print \"Appended-------------------------------------------------------------------------------\"\n",
    "        #print currNovTrialAllExtData.shape\n",
    "        extractedNovData.append(currNovTrialAllExtData)\n",
    "        #print extractedNovData\n",
    "        #print \"END-------------------------------------------------------------------------------------\"\n",
    "    \n",
    "#print currentNovData\n",
    "\n",
    "noviceDataArray = np.array(currentNovData)\n",
    "noviceExtractedDataArray = np.array(extractedNovData)\n",
    "print noviceExtractedDataArray.shape\n",
    "#print noviceDataArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34L, 20L)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Consolidate all data \n",
    "allData = np.concatenate((expertDataArray,noviceDataArray), axis=0)\n",
    "#allData.shape\n",
    "\n",
    "#Consolidate feature extracted data\n",
    "allExtractedData = np.concatenate((expertExtractedDataArray,noviceExtractedDataArray),axis=0)\n",
    "allExtractedData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create labels\n",
    "#expert_rows, expert_columns = expertDataArray.shape\n",
    "#print expert_rows\n",
    "#expert_labels = np.zeros(expert_rows,)\n",
    "#print expert_labels\n",
    "#novice_rows, novice_columns = noviceDataArray.shape\n",
    "#print novice_rows\n",
    "#novice_labels = np.ones(novice_rows,)\n",
    "#print novice_labels\n",
    "\n",
    "#all_labels = np.concatenate((expert_labels,novice_labels), axis=0)\n",
    "#print all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#Create labels\n",
    "expert_rows, expert_columns = expertExtractedDataArray.shape\n",
    "#print expert_rows\n",
    "expert_labels = np.zeros(expert_rows,)\n",
    "#print expert_labels\n",
    "novice_rows, novice_columns = noviceExtractedDataArray.shape\n",
    "#print novice_rows\n",
    "novice_labels = np.ones(novice_rows,)\n",
    "#print novice_labels\n",
    "\n",
    "all_labels = np.concatenate((expert_labels,novice_labels), axis=0)\n",
    "print all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, cross_validation, neighbors, svm, tree\n",
    "Data_train, Data_test, Labels_train, Labels_test = cross_validation.train_test_split(allExtractedData, all_labels, test_size=0.2)\n",
    "\n",
    "#KNN\n",
    "knn_classifier = neighbors.KNeighborsClassifier()\n",
    "knn_classifier.fit(Data_train, Labels_train)\n",
    "knn_classifier.fit(Data_test, Labels_test)\n",
    "knn_score = knn_classifier.score(Data_test, Labels_test)\n",
    "print knn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "svm_classifier = svm.SVC(kernel='linear', C = 1.0)\n",
    "svm_classifier.fit(Data_train, Labels_train)\n",
    "svm_classifier.fit(Data_test, Labels_test)\n",
    "svm_score = svm_classifier.score(Data_test, Labels_test)\n",
    "print svm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#DTree\n",
    "dt_classifier = tree.DecisionTreeClassifier()\n",
    "dt_classifier.fit(Data_train, Labels_train)\n",
    "dt_classifier.fit(Data_test, Labels_test)\n",
    "dtree_score = dt_classifier.score(Data_test, Labels_test)\n",
    "print dtree_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
